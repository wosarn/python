{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://sigdelta.com/assets/images/sages-sd-logo.png)\n",
    "\n",
    "# Analiza danych i uczenie maszynowe w Python\n",
    "\n",
    "Autor notebooka: Jakub Nowacki.\n",
    "\n",
    "## Dane tekstowe\n",
    "\n",
    "W tym notebooku przedstawiamy metody pracy z danymi tekstowymi, zarówno używając czystego języka Python, jak i dostępnych pakietów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: dracula\n",
      "Raw data: ﻿The Project Gutenberg EBook of Dracula, by Bram Stoker\n",
      "\n",
      "This eBook is for the use of anyone anywher\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "data_dir = 'data/books'\n",
    "\n",
    "books = list()\n",
    "for file_name in glob.glob(os.path.join(data_dir, '*.txt')):\n",
    "    with open(file_name, encoding='utf-8') as lines:\n",
    "        book_name = re.split(r'[\\\\\\/]+', file_name)[-1].replace('.txt', '')\n",
    "        books.append({'book': book_name, 'raw': lines.read()})\n",
    "\n",
    "print('Book:', books[0]['book'])\n",
    "print('Raw data:', books[0]['raw'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffThe Project Gutenberg EBook of Dracula, by Bram Stoker\\n\\nThis eBook is for the use of anyone anywher'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dracula = books[0]['raw']\n",
    "\n",
    "dracula[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział na wyrazy\n",
    "\n",
    "Dokument, taki jak książka Dracula, możemy podzielić na zdania lub wyrazy (tokeny). \n",
    "\n",
    "Podstawowym rozwiązaniem jest używanie metod obiektu `str`, np. `split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Dracula,',\n",
       " 'by',\n",
       " 'Bram',\n",
       " 'Stoker',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever.',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dracula[:200].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym rozwiązaniem są wyrażenia regularne (ang. [regular expressions](https://en.wikipedia.org/wiki/Regular_expression)) dostępne są bodaj we wszystkich językach programowania i są powszechnie używane w pracy z tekstem. Pisanie wyrażeń regularnych jest bardzo podobne w wielu językach, niemniej warto czasem wspomagać się dostępnymi narzędziami, takimi jak [regex101.com](https://regex101.com/).\n",
    "\n",
    "Wyrażenia regularne w Pythonie są częścią standardowej biblioteki i mają nazwę [`re`](https://docs.python.org/3/library/re.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Dracula',\n",
       " 'by',\n",
       " 'Bram',\n",
       " 'Stoker',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're',\n",
       " 'use',\n",
       " 'it']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re.findall('\\w+', dracula[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowe narzędzia, np NLTK dostarczają dedykowane narzędzia do pracy z tekstem. Wyczerpujący opis można znaleźć [w dokumentacji NLTK](http://www.nltk.org/book/ch03.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe Project Gutenberg EBook of Dracula, by Bram Stoker\\n\\nThis eBook is for the use of anyone anywhere at no cost and with\\nalmost no restrictions whatsoever.',\n",
       " 'You may copy it, give it away or\\nre-use it under the terms of the Project Gutenberg License included\\nwith this eBook or online at www.gutenberg.org/license\\n\\n\\nTitle: Dracula\\n\\nAuthor: Bram Stoker\\n\\nRelease Date: August 16, 2013 [EBook #345]\\n\\nLanguage: English\\n\\n\\n*** START OF THIS PROJECT GUTENBERG EBOOK DRACULA ***\\n\\n\\n\\n\\nProduced by Chuck Greif and the Online Distributed\\nProofreading Team at http://www.pgdp.net (This file was\\nproduced from images generously made available by The\\nInternet Archive)\\n\\n\\n\\n\\n\\n\\n\\n                                DRACULA\\n\\n\\n\\n\\n\\n                                DRACULA\\n\\n                                  _by_\\n\\n                              Bram Stoker\\n\\n                        [Illustration: colophon]\\n\\n                                NEW YORK\\n\\n                            GROSSET & DUNLAP\\n\\n                              _Publishers_\\n\\n      Copyright, 1897, in the United States of America, according\\n                   to Act of Congress, by Bram Stoker\\n\\n                        [_All rights reserved._]\\n\\n                      PRINTED IN THE UNITED STATES\\n                                   AT\\n               THE COUNTRY LIFE PRESS, GARDEN CITY, N.Y.\\n\\n\\n\\n\\n                                   TO\\n\\n                             MY DEAR FRIEND\\n\\n                               HOMMY-BEG\\n\\n\\n\\n\\nCONTENTS\\n\\n\\nCHAPTER I\\n                                                                    Page\\n\\nJonathan Harker\\'s Journal                                              1\\n\\nCHAPTER II\\n\\nJonathan Harker\\'s Journal                                             14\\n\\nCHAPTER III\\n\\nJonathan Harker\\'s Journal                                             26\\n\\nCHAPTER IV\\n\\nJonathan Harker\\'s Journal                                             38\\n\\nCHAPTER V\\n\\nLetters--Lucy and Mina                                                51\\n\\nCHAPTER VI\\n\\nMina Murray\\'s Journal                                                 59\\n\\nCHAPTER VII\\n\\nCutting from \"The Dailygraph,\" 8 August                               71\\n\\nCHAPTER VIII\\n\\nMina Murray\\'s Journal                                                 84\\n\\nCHAPTER IX\\n\\nMina Murray\\'s Journal                                                 98\\n\\nCHAPTER X\\n\\nMina Murray\\'s Journal                                                111\\n\\nCHAPTER XI\\n\\nLucy Westenra\\'s Diary                                                124\\n\\nCHAPTER XII\\n\\nDr. Seward\\'s Diary                                                   136\\n\\nCHAPTER XIII\\n\\nDr. Seward\\'s Diary                                                   152\\n\\nCHAPTER XIV\\n\\nMina Harker\\'s Journal                                                167\\n\\nCHAPTER XV\\n\\nDr. Seward\\'s Diary                                                   181\\n\\nCHAPTER XVI\\n\\nDr. Seward\\'s Diary                                                   194\\n\\nCHAPTER XVII\\n\\nDr. Seward\\'s Diary                                                   204\\n\\nCHAPTER XVIII\\n\\nDr. Seward\\'s Diary                                                   216\\n\\nCHAPTER XIX\\n\\nJonathan Harker\\'s Journal                                            231\\n\\nCHAPTER XX\\n\\nJonathan Harker\\'s Journal                                            243\\n\\nCHAPTER XXI\\n\\nDr. Seward\\'s Diary                                                   256\\n\\nCHAPTER XXII\\n\\nJonathan Harker\\'s Journal                                            269\\n\\nCHAPTER XXIII\\n\\nDr. Seward\\'s Diary                                                   281\\n\\nCHAPTER XXIV\\n\\nDr. Seward\\'s Phonograph Diary, spoken by Van Helsing                 294\\n\\nCHAPTER XXV\\n\\nDr. Seward\\'s Diary                                                   308\\n\\nCHAPTER XXVI\\n\\nDr. Seward\\'s Diary                                                   322\\n\\nCHAPTER XXVII\\n\\nMina Harker\\'s Journal                                                338\\n\\n\\n\\n\\nDRACULA\\n\\n\\n\\n\\nCHAPTER I\\n\\nJONATHAN HARKER\\'S JOURNAL\\n\\n(_Kept in shorthand._)\\n\\n\\n_3 May.',\n",
       " 'Bistritz._--Left Munich at 8:35 P. M., on 1st May, arriving at\\nVienna early next morning; should have arrived at 6:46, but train was an\\nhour late.',\n",
       " 'Buda-Pesth seems a wonderful place, from the glimpse which I\\ngot of it from the train and the little I could walk through the\\nstreets.',\n",
       " 'I feared to go very far from the station, as we had arrived\\nlate and would start as near the correct time as possible.',\n",
       " 'The\\nimpression I had was that we were leaving the West and entering the\\nEast; the most western of splendid bridges over the Danube, which is\\nhere of noble width and depth, took us among the traditions of Turkish\\nrule.',\n",
       " 'We left in pretty good time, and came after nightfall to Klausenburgh.',\n",
       " 'Here I stopped for the night at the Hotel Royale.',\n",
       " 'I had for dinner, or\\nrather supper, a chicken done up some way with red pepper, which was\\nvery good but thirsty.',\n",
       " '(_Mem._, get recipe for Mina.)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = nltk.sent_tokenize(dracula)\n",
    "\n",
    "sents[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8569"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffThe',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Dracula',\n",
       " ',',\n",
       " 'by',\n",
       " 'Bram',\n",
       " 'Stoker']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.word_tokenize(dracula)\n",
    "\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193771"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'Dracula',\n",
       " 'by',\n",
       " 'Bram',\n",
       " 'Stoker',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize(dracula, '\\w+')[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby znormalizować dokumenty możemy zmienić rozmiar znaków i ew usunąć elementy niepasujące naszej definicji wyrazu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffthe',\n",
       " 'project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'dracula',\n",
       " ',',\n",
       " 'by',\n",
       " 'bram',\n",
       " 'stoker',\n",
       " 'this',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower() for w in words[:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['project',\n",
       " 'gutenberg',\n",
       " 'ebook',\n",
       " 'of',\n",
       " 'dracula',\n",
       " 'by',\n",
       " 'bram',\n",
       " 'stoker',\n",
       " 'this',\n",
       " 'ebook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower() for w in words[:20] if re.match('\\w+', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Podziel całą książkę Dracula na wyrazy; znajdź unikalne wyrazy.\n",
    "1. Znormalizuje wyrazy; znajdź unikalne wyrazy i zobacz czy lista się zmieniła.\n",
    "1. ★ Zbuduj listę słowników z parami książka-wyraz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zliczanie słów\n",
    "\n",
    "Jednym z podstawowych zadań, które wykonuje się przy analizie danych tekstowych. Python oferuje wiele rozwiązań tego problemu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_dict = dict()\n",
    "\n",
    "for word in nltk.word_tokenize(dracula):\n",
    "    w = word.lower()\n",
    "    if w in word_dict:\n",
    "        word_dict[w] += 1\n",
    "    else:\n",
    "        word_dict[w] = 1\n",
    "\n",
    "list(word_dict.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counter = Counter(nltk.word_tokenize(dracula))\n",
    "\n",
    "list(word_counter.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counter = Counter(word_dict)\n",
    "\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counter = Counter()\n",
    "\n",
    "for word in nltk.word_tokenize(dracula):\n",
    "    w = word.lower()\n",
    "    word_counter[w] += 1\n",
    "\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest też rozszerzona wersja `Counter` w NLTK nazwana [`FreqDist`](http://www.nltk.org/api/nltk.html#nltk.probability.FreqDist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counter = nltk.FreqDist()\n",
    "\n",
    "for word in nltk.word_tokenize(dracula):\n",
    "    w = word.lower()\n",
    "    word_counter[w] += 1\n",
    "\n",
    "word_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 'the'\n",
    "print('Częstotliwość słowa \"{}\": {}'.format(w, word_counter.freq(w)))\n",
    "print('Ilość wszystkich słów: {}'.format(word_counter.N()))\n",
    "print('Ilość unikalnych słów: {}'.format(word_counter.B()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "*Stop words* (po polsku czasami używa się określenia stop lista) to są najpopularniejsze słowa w danym języku, które nie wnoszą dodatkowej informacji przy analizie. W analizie językowej wyrazy ze stop listy najczęściej usuwa się ze zbioru.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\"],\n",
       " list,\n",
       " 179)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stop_words[:10], type(stop_words), len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(frozenset, 179)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = frozenset(stop_words)\n",
    "\n",
    "type(stop_words), len(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Policz wyrazy w książce Dracula usuwając wyrazy ze stop listy.\n",
    "1. Usuń *nie-wyrazy* z licznika."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolokacja i n-gramy\n",
    "\n",
    "Ważną analizą struktury dokumentów jest kolokacja, czyli występujące koło siebie słowa. Obiekty te nazywamy n-gramami, gdzie *n* to szerokość okna. Przykładowo przy szerokości okna 2 rozpatrujemy dwa słowa koło siebie; taki element nazywamy bigramem i jest on najczęściej stosowany w analizie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary', 'had', 'a', 'little', 'lamb']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = nltk.word_tokenize('Mary had a little lamb')\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mary', 'had'), ('had', 'a'), ('a', 'little'), ('little', 'lamb')]\n",
      "<class 'zip'>\n"
     ]
    }
   ],
   "source": [
    "bigrams = zip(sample, sample[1:])\n",
    "print(list(bigrams))\n",
    "print(type(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Mary', 'had'), ('had', 'a'), ('a', 'little'), ('little', 'lamb')]\n",
      "<class 'generator'>\n"
     ]
    }
   ],
   "source": [
    "bigrams = nltk.bigrams(sample)\n",
    "print(list(bigrams))\n",
    "print(type(bigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Policz bigramy w książce Dracula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Większość powyższych przykładów operowała głównie na kolekcjach Pythonowych. Z kolei w poprzednich notebookach pokazaliśmy, że Pandas ma wiele użytecznych elementów do pracy z danymi. Poniżej pokażemy kilka przykładów pracy z danymi tekstowymi w Pandas. Zacznijmy od przekształcenia naszej książki Dracula w DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dracula</td>\n",
       "      <td>﻿The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dracula</td>\n",
       "      <td>Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dracula</td>\n",
       "      <td>Gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dracula</td>\n",
       "      <td>EBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dracula</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book      words\n",
       "0  dracula       ﻿The\n",
       "1  dracula    Project\n",
       "2  dracula  Gutenberg\n",
       "3  dracula      EBook\n",
       "4  dracula         of"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dracula_df = pd.DataFrame({\n",
    "    'book': 'dracula',\n",
    "    'words': nltk.word_tokenize(dracula)\n",
    "})\n",
    "dracula_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas ma swoje własne metody do pracy z danymi tekstowymi, ukryte pod właściwością `Series.str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ﻿the\n",
       "1      project\n",
       "2    gutenberg\n",
       "3        ebook\n",
       "4           of\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dracula_df.words.str.lower().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy też aplikować funkcje do kolumny używając przykładowo funkcji `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ﻿the\n",
       "1      project\n",
       "2    gutenberg\n",
       "3        ebook\n",
       "4           of\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dracula_df.words.apply(lambda w: w.lower()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oraz zapisać wynik do pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dracula_df.to_hdf('data/dracula.h5', 'words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy też zrobić i zapisać bigramy jako osobną tabelę. W tym przypadku łatwiej po prostu stworzyć nowy DataFrame z bigramami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigrams</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(﻿The, Project)</td>\n",
       "      <td>dracula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Project, Gutenberg)</td>\n",
       "      <td>dracula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Gutenberg, EBook)</td>\n",
       "      <td>dracula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(EBook, of)</td>\n",
       "      <td>dracula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(of, Dracula)</td>\n",
       "      <td>dracula</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bigrams     book\n",
       "0       (﻿The, Project)  dracula\n",
       "1  (Project, Gutenberg)  dracula\n",
       "2    (Gutenberg, EBook)  dracula\n",
       "3           (EBook, of)  dracula\n",
       "4         (of, Dracula)  dracula"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dracula_bigrams = pd.DataFrame({\n",
    "    'book': 'dracula',\n",
    "    'bigrams': list(nltk.bigrams(dracula_df.words))\n",
    "})\n",
    "\n",
    "dracula_bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dracula_bigrams.to_hdf('data/dracula.h5', 'bigrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf('data/dracula.h5', 'bigrams').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_hdf('data/dracula.h5', 'words').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Wczytaj zapisane tabele i zobacz czy są poprawne.\n",
    "1. Usuń słowa ze stop listy i zapisz dokument jeszcze raz.\n",
    "1. Wygeneruj bigramy bez stop wordów.\n",
    "1. Znormalizuj słowa w bigramach.\n",
    "1. ★ Usuń ostrzeżenie PyTables.\n",
    "1. ★ Sprawdź czy bigramy są poprawnie wygenerowane i jednoznaczne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstrakcja danych tekstowych\n",
    "\n",
    "Powróćmy do danych tabelarycznych Movie Lens. Część tabel, w szczególności Movie ma zagnieżdżone dane tekstowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('data/ml-latest-small/movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy wyciągnąć rok produkcji filmu używając metod we właściwości serii `str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies.title.str.extract('\\((\\d\\d\\d\\d)\\)', 1, expand=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies['year'] = movies.title.str.extract('\\((\\d\\d\\d\\d)\\)', 1, expand=False)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy też wyszukiwać po nazwie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies[movies.genres.str.match('Comedy')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy też podzielić tekst i dostać kolekcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies['genres_array'] = movies.genres.str.split('|')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy przykładowo wypłaszczyć taką zagnieżdżoną tablicę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies['genres_array'].apply(pd.Series).stack().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Wyświetl ilość filmów wydanych każdego roku; na wykresie wygląda to lepiej.\n",
    "1. Ile filmów to filmy akcji dla dzieci?\n",
    "1. Ile filmów dla dzieci robi się średnio w roku?\n",
    "1. Ile jest unikalnych kategorii?\n",
    "1. ★ Policz liczbę filmów dla danej kategorii.\n",
    "1. ★ Policz średnią ocenę filmu (rating) dla danej kategorii."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
