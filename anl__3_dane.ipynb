{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://sigdelta.com/assets/images/sages-sd-logo.png)\n",
    "\n",
    "# Analiza danych i uczenie maszynowe w Python\n",
    "\n",
    "Autor notebooka: Jakub Nowacki.\n",
    "\n",
    "## Dane\n",
    "\n",
    "Notebook prezentuje różne metody pozyskiwania danych do analiz. Ponadto, prezentujemy najpopularniejsze metody czytania i zapisywania plików z danymi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z sieci\n",
    "\n",
    "Wiele danych dostępnych jest jako zbiory zdalne na różnych serwerach. Mowa tu o otwartych zbiorach danych ale też zbiorach dostępnych w różnych organizacjach. Python posiada szereg narzędzi do pozyskiwania ogólnych danych z sieci. \n",
    "\n",
    "### `urllib.request`\n",
    "\n",
    "Pakiet [`urllib.request`](https://docs.python.org/3/library/urllib.request.html) jest częścią standardowej biblioteki Pythona i służy do pracy ze zdalnymi serwerami operującymi protokołami HTTP(S) i FTP. Jest to protokół dość niskopoziomowy, więc jego używanie nie zawsze bywa bardzo proste, niemniej, ma wiele przydatnych funkcji. Najlepiej używać go, kiedy nie mamy pewności czy inne pakiety są zainstalowane w dystrybucji Pythona. \n",
    "\n",
    "Poniżej przykład użycia funkcji `urlretrieve`, która pobiera zawartość URLa do pliku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bf994718334ac984a9e1db7b1224df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "data_dir = 'data/books'\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "book_files = {\n",
    "    'grimms_fairy_tales': 'http://www.gutenberg.org/files/2591/2591-0.txt', \n",
    "    'dracula': 'http://www.gutenberg.org/cache/epub/345/pg345.txt',\n",
    "    'frankenstein': 'http://www.gutenberg.org/cache/epub/84/pg84.txt', \n",
    "    'moby_dick': 'http://www.gutenberg.org/files/2701/2701-0.txt',\n",
    "    'tom_sawyer': 'http://www.gutenberg.org/files/74/74-0.txt',\n",
    "    'war_and_peace': 'http://www.gutenberg.org/files/2600/2600-0.txt'\n",
    "}\n",
    "\n",
    "for book, url in tqdm_notebook(book_files.items()):\n",
    "    dest_file = os.path.join(data_dir, '{}.txt'.format(book))\n",
    "    urllib.request.urlretrieve(url, dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requests\n",
    "\n",
    "Pakiet [Requests](http://docs.python-requests.org/en/master/) jest pakietem ogólnego przeznaczenia do komunikacji z użyciem protokołu HTTP(S). Jest on wysokopoziomowym pakietem, który zdejmuje dużo operacji z użytkownika. W razie jak jest dostępny, jest zalecany nawet przez dokumentację `urllib`.  \n",
    "\n",
    "Do bardziej rozbudowanego i regularnego pozyskiwania danych ze stron internetowych można wykorzystać bardziej zaawansowane pakiety, takie jak [Scrapy](https://scrapy.org/)\n",
    "\n",
    "Poniżej przykład czytania książki z Projektu Gutenberg bezpośrednio z URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104148"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.gutenberg.org/files/2591/2591-0.txt'\n",
    "\n",
    "r = requests.get(url)\n",
    "#r\n",
    "##r.content\n",
    "#r.content.decode(r.encoding)\n",
    "#r.text\n",
    "len(r.text.split())\n",
    "len(r.text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kod statusu: 200\n",
      "Nagłówki: {'Server': 'Apache', 'Set-Cookie': 'session_id=090fd54f3c60220930f2fa703fbf33c021cf4ed9; Domain=.gutenberg.org; expires=Wed, 14 Feb 2018 08:35:26 GMT; Path=/', 'X-Rate-Limiter': 'zipcat2.php', 'Vary': 'negotiate,accept-encoding', 'Last-Modified': 'Mon, 07 November 2016 11:13:50 GMT', 'ETag': '\"56bc3516\"', 'Content-Encoding': 'gzip', 'X-Zipcat': '194297 / 560166 = 0.347', 'Accept-Ranges': 'none', 'X-Frame-Options': 'sameorigin', 'X-Connection': 'Close', 'Content-Type': 'text/plain; charset=UTF-8', 'X-Powered-By': '1', 'Content-Length': '194297', 'Date': 'Wed, 14 Feb 2018 08:05:26 GMT', 'X-Varnish': '281978112', 'Age': '0', 'Via': '1.1 varnish'}\n",
      "Ciasteczka: {'session_id': '090fd54f3c60220930f2fa703fbf33c021cf4ed9'}\n",
      "Kodowanie: UTF-8\n",
      "Zawartość: b'\\xef\\xbb\\xbfThe Project Gutenberg EBook of Grimms\\xe2\\x80\\x99 Fairy Tales, by The Brothers Grimm\\r\\n\\r\\nThis eBook is for '...\n"
     ]
    }
   ],
   "source": [
    "print('Kod statusu: {}'.format(r.status_code))\n",
    "print('Nagłówki: {}'.format(r.headers))\n",
    "print('Ciasteczka: {}'.format(r.cookies.get_dict()))\n",
    "print('Kodowanie: {}'.format(r.encoding))\n",
    "print('Zawartość: {}...'.format(r.content[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Policz ile słów (w sumie) jest w pobranej książce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Parsowanie HTML\n",
    "\n",
    "Niekiedy istnieje potrzeba parsowania zawartości strony w postaci HTML do bardziej przyjaznej formy. Pakiety jak Requests pozwalają na łatwe czytanie źródła strony, niemniej, niekiedy interesujące nas dane znajdują się w konkretnym jej miejscu. Najpopularniejszą biblioteką w Pythonie do parsowanie HTML i XML jest [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head><title>The Dormouse's story</title></head>\n",
       "<body>\n",
       "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
       "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "and they lived at the bottom of a well.</p>\n",
       "<p class=\"story\">...</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "\"\"\"\n",
    "\n",
    "soup = bs4.BeautifulSoup(html_doc, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class': ['title']}\n",
      "[<b>The Dormouse's story</b>]\n",
      "{'class': ['story']}\n",
      "['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, ';\\nand they lived at the bottom of a well.']\n",
      "{'class': ['story']}\n",
      "['...']\n"
     ]
    }
   ],
   "source": [
    "for p in soup.find_all('p'):\n",
    "    print(p.attrs)\n",
    "    print(p.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'http://example.com/elsie', 'class': ['sister'], 'id': 'link1'}\n",
      "['Elsie']\n",
      "{'href': 'http://example.com/lacie', 'class': ['sister'], 'id': 'link2'}\n",
      "['Lacie']\n",
      "{'href': 'http://example.com/tillie', 'class': ['sister'], 'id': 'link3'}\n",
      "['Tillie']\n"
     ]
    }
   ],
   "source": [
    "for a in soup.find_all('a'):\n",
    "    print(a.attrs)\n",
    "    print(a.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Dormouse's story\\n\\nThe Dormouse's story\\nOnce upon a time there were three little sisters; and their names were\\nElsie,\\nLacie and\\nTillie;\\nand they lived at the bottom of a well.\\n...\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Przeczytaj zawartość linka http://sigdelta.com/blog/how-to-install-pyspark-locally/\n",
    "1. Ile razy pojawia się słowo Spark?\n",
    "1. Pokaż wszystkie nagłówki sekcji\n",
    "1. ★ Wypisz zawartość bloków kodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-d5a8f6127906>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-d5a8f6127906>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    r.text(:100)\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "r=request.get('http://sigdelta.com/blog/how-to-install-pyspark-locally/')\n",
    "r\n",
    "r.text(:100)\n",
    "doc=bs4.BeautifulSoup(r.text,'lxml')\n",
    "doc.text\n",
    "len(doc.text.lower().split('spark')-1\n",
    "import re\n",
    "re.findall('spark',doc.text,flags=re.IGNORCASE)\n",
    "for h indoc.find_all(('h1','h2','h3'))\n",
    "    print(h.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter\n",
    "\n",
    "Wiele usług sieciowych dostarcza API do łączenia się z nimi. Jednym z najpopularniejszych metod projektowania API jest [RESTful](https://en.wikipedia.org/wiki/Representational_state_transfer), który posługuje się protokołem HTTP. Do połączenia z takim API można wykorzystać bibliotekę Requests. Niemniej, istnieje wiele dedykowanych bibliotek do pracy z publicznymi API.\n",
    "\n",
    "Twitter, jak wiele innych sieci społecznościowych, daje zdalny dostęp do swoich danych przez [swoje API](https://developer.twitter.com/en/docs). Wprawdzie Twitter sam nie dostarcza klienta Pythonowego, dostępne jest [wiele bibliotek](https://developer.twitter.com/en/docs/developer-utilities/twitter-libraries) do pracy z API. Jedną z najbardziej popularnych w języku Python jest [Tweepy](http://www.tweepy.org/).\n",
    "\n",
    "Do wielu API publicznych wymagana jest autentykacja; najczęściej wykorzystywanym protokołem jest OAuth z zestawem kluczy. Aby uzyskać klucze należy zarejestrować się na stronie [apps.twitter.com](apps.twitter.com) jak opisano [w dokumentacji](https://developer.twitter.com/en/docs/basics/authentication/guides/access-tokens). W poniższym przykładzie klucze czytane są z pliku `tweepy_conf.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import tweepy_conf as tc\n",
    "\n",
    "auth = tweepy.OAuthHandler(tc.consumer_key, tc.consumer_secret)\n",
    "auth.set_access_token(tc.access_token, tc.access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można wyświetlić tweety z własnej strony domowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(\"text: {}\".format(tweet.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można też użyć innych API np. [Search API](https://developer.twitter.com/en/docs/tweets/search/overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tweet in api.search('python'):\n",
    "    print(\"text: {}\".format(tweet.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = api.search('python')[0]\n",
    "\n",
    "print('Tweet ID: {0} (https://twitter.com/statuses/{0}),'.format(t.id))\n",
    "print('Autor: {}'.format(t.author.name))\n",
    "print('Data utworzenia: {}'.format(t.created_at))\n",
    "print('Tekst: {}'.format(t.text))\n",
    "print('Ile razy przekazywany: {}'.format(t.retweet_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Wypisz tweety w kolejności ilości przekazań (retweetów).\n",
    "1. Wypisz wszystkich unikalnych autorów tweetów.\n",
    "1. ★ Znajdź i policz wszystkie hashtagi twittach o Pythonie.\n",
    "1. ★ Wyświetl 100 tweetów dla języka polskiego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Istniejące zbiory danych\n",
    "\n",
    "Oprócz powszechnie dostępnych zbiorów danych w sieci, dostępne jest wiele przetworzonych form danych w pakietach Pythonowych. Poniżej prezentujemy wybór takich źródeł danych z naciskiem na dane tekstowe. Generalnie, ilość dostępnych danych szybko rośnie, więc warto obserwować informacje ze źródeł piszących o Data Science.\n",
    "\n",
    "### NLTK\n",
    "\n",
    "Głównym źródłem zbiorów danych tekstowych, czyli korpusów, jest NLTK. Wyczerpujący opis zbioru możemy znaleźć [w manualu NLTK](http://www.nltk.org/book/ch02.html). Wyróżnić można kilka typów korpusów, co zostało przedstawione na poniższym rysunku.\n",
    "\n",
    "![](http://www.nltk.org/images/text-corpus-structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book = 'shakespeare-macbeth.txt'\n",
    "\n",
    "print('Raw:')\n",
    "print(nltk.corpus.gutenberg.raw(book)[:100])\n",
    "print('\\nSents:')\n",
    "print(nltk.corpus.gutenberg.sents(book)[:3])\n",
    "print('\\nWords:')\n",
    "print(nltk.corpus.gutenberg.words(book)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Brown corpus lengths:')\n",
    "print('len(all) = {:,}'.format(len(brown.words())))\n",
    "for c in brown.categories():\n",
    "    print('len({}) = {:,}'.format(c, len(brown.words(categories=c))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inne zbiory\n",
    "\n",
    "Inne pakiety również dostarczają gotowe zbiory danych:\n",
    "\n",
    "* [`sklearn.datasets`](http://scikit-learn.org/stable/datasets/)\n",
    "    * [20 Newsgroups](http://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset)\n",
    "* [Kaggle](https://www.kaggle.com)\n",
    "    * [Twitter Airline Sentiment](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)\n",
    "    * [Kaggle Survey 2017](https://www.kaggle.com/kaggle/kaggle-survey-2017)\n",
    "* [Dane Stack Exchange](https://archive.org/details/stackexchange)\n",
    "* [UCI Machine Learning Repository](https://archive.ics.uci.edu/)\n",
    "    * [Zbiory tekstowe](https://archive.ics.uci.edu/ml/datasets.html?format=&task=&att=&area=&numAtt=&numIns=&type=text&sort=nameUp&view=table)\n",
    "* [Lista zbiorów danych do NLP](https://github.com/niderhoff/nlp-datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie \n",
    "\n",
    "1. Zamień korpus Browna ze słowami i kategoriami na DataFrame Pandas.\n",
    "1. Ile jest słów dla każdej kategorii.\n",
    "1. Czy są jakieś wspólne słowa dla kategorii? Podaj przykłady."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas ma szerokie możliwości czytania i zapisywania danych w różnych formatach. Wprawdzie niewiele z wymienionych danych powyżej jest w formacje Pandas, są one najczęściej w formatach które Pandas potrafi albo łatwo czytać, albo da je się łatwo przerobić na DataFrame. Aby sprawdzić wszystkie typy, zobacz [dokumentację](https://pandas.pydata.org/pandas-docs/stable/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for method in dir(pd):\n",
    "    if method.startswith('read'):\n",
    "        print('*** {} ***'.format(method))\n",
    "        doc_lines = getattr(pd, method).__doc__.split('\\n')\n",
    "        if doc_lines[0]:\n",
    "            print(doc_lines[0].strip())\n",
    "        else:\n",
    "            print(doc_lines[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Dracula, by Bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This eBook is for the use of anyone anywhere a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>almost no restrictions whatsoever.  You may co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>re-use it under the terms of the Project Guten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with this eBook or online at www.gutenberg.org...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lines\n",
       "0  The Project Gutenberg EBook of Dracula, by Bra...\n",
       "1  This eBook is for the use of anyone anywhere a...\n",
       "2  almost no restrictions whatsoever.  You may co...\n",
       "3  re-use it under the terms of the Project Guten...\n",
       "4  with this eBook or online at www.gutenberg.org..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = pd.read_table('data/books/dracula.txt', names=['lines'])\n",
    "book.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'book': 'dracula',\n",
       "  'line': '\\ufeffThe Project Gutenberg EBook of Dracula, by Bram Stoker\\n'},\n",
       " {'book': 'dracula', 'line': '\\n'},\n",
       " {'book': 'dracula',\n",
       "  'line': 'This eBook is for the use of anyone anywhere at no cost and with\\n'},\n",
       " {'book': 'dracula',\n",
       "  'line': 'almost no restrictions whatsoever.  You may copy it, give it away or\\n'},\n",
       " {'book': 'dracula',\n",
       "  'line': 're-use it under the terms of the Project Gutenberg License included\\n'},\n",
       " {'book': 'dracula',\n",
       "  'line': 'with this eBook or online at www.gutenberg.org/license\\n'},\n",
       " {'book': 'dracula', 'line': '\\n'},\n",
       " {'book': 'dracula', 'line': '\\n'},\n",
       " {'book': 'dracula', 'line': 'Title: Dracula\\n'},\n",
       " {'book': 'dracula', 'line': '\\n'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "data_dir = 'data/books'\n",
    "\n",
    "books = list()\n",
    "for file_name in glob.glob(os.path.join(data_dir, '*.txt')):\n",
    "    with open(file_name, encoding='utf-8') as lines: #zwraca wskaznik do pliku\n",
    "                                                     #alternatywnie lines=open... ale wtedy trzebaby na koncu zamykac plik\n",
    "        book_name = file_name.split(os.path.sep)[-1].replace('.txt', '')\n",
    "        for line in lines:\n",
    "            books.append({'book': book_name, 'line': line})\n",
    "books[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = pd.DataFrame(books)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books.groupby('book').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for method in dir(books):\n",
    "    if method.startswith('to_'):\n",
    "        print('*** {} ***'.format(method))\n",
    "        doc_lines = getattr(books, method).__doc__.split('\\n')\n",
    "        if doc_lines[0]:\n",
    "            print(doc_lines[0].strip())\n",
    "        else:\n",
    "            print(doc_lines[1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "\n",
    "1. Zapisz DataFrame `books` jako plik w 2 wybranych formatach, najlepiej 1 tekstowym i 1 binarnym; porównaj pliki.\n",
    "1. Odczytaj dane z zapisanego pliku; czy coś się zmieniło?\n",
    "1. ★ Sprawdź czy da się odczytać plik prosto z sieci.\n",
    "1. ★ Zamień dane z korpusu Browna na DataFrame Pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
